{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veiro/Extentend_Data_imputation_with_CTGAN/blob/main/Conditional_GANs_for_Synthetic_Ranking_Data_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI1a0DMgzsi9"
      },
      "source": [
        "Nov 1, 2019\n",
        "\n",
        "Conditional Imputation GAN on synthetic ranking data. Please do not distribute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_VYRYhcXX0o"
      },
      "source": [
        "### Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s8g1lXYXX0e"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from tqdm import tqdm\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x5TnkqZkubH",
        "outputId": "c7b49c1e-7e09-4c78-b173-89c871ee89eb"
      },
      "source": [
        "%%time\n",
        "train_filepath = 'https://raw.githubusercontent.com/gdeng96/cond-imp-gan-ranking/main/synthetic_ranking_data.csv'#'~/synthetic_ranking_data_train.csv'\n",
        "test_filepath = 'https://raw.githubusercontent.com/gdeng96/cond-imp-gan-ranking/main/synthetic_ranking_data.csv'#'~/synthetic_ranking_data_test.csv'\n",
        "train_df = pandas.read_csv(train_filepath)\n",
        "test_df = pandas.read_csv(test_filepath) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.13 s, sys: 207 ms, total: 2.34 s\n",
            "Wall time: 2.74 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "data_filepath = 'https://raw.githubusercontent.com/gdeng96/cond-imp-gan-ranking/main/synthetic_ranking_data.csv'\n",
        "data_full = pandas.read_csv(data_filepath)\n",
        "data =  data_full.sample(n=100000, random_state=1)\n",
        "train_df, test_df = train_test_split(data, test_size=0.10, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe-Xcs2qqVR3",
        "outputId": "c4b69645-667e-464a-e127-17100b0ddda6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.3 s, sys: 119 ms, total: 1.42 s\n",
            "Wall time: 1.55 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFLmBK1-XX0p"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxshtHy3XX0p"
      },
      "source": [
        "INFO_COLS = ['Category', \"QID\", \"ProductID\", \"QProductID\"]\n",
        "RANKING_COLS = [\"V5\", \"V6\", \"V7\", \"V8\", \"V9\"]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXBE-FgMXX0p",
        "outputId": "a2ae5859-c03d-4161-ce65-70a0f019eed6"
      },
      "source": [
        "%%time\n",
        "trainX = train_df.loc[:, RANKING_COLS]\n",
        "testX = test_df.loc[:, RANKING_COLS]\n",
        "\n",
        "#Normalize features\n",
        "trainX_mean = trainX.mean()\n",
        "trainX_sd = trainX.std()\n",
        "testX_mean = testX.mean()\n",
        "testX_sd = testX.std()\n",
        "\n",
        "trainX =(trainX-trainX.mean())/trainX.std()\n",
        "testX =(testX-testX.mean())/testX.std()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 33.5 ms, sys: 1.06 ms, total: 34.6 ms\n",
            "Wall time: 37.3 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfr9wIdwXX0q",
        "outputId": "a06806e6-2bcd-4445-9dde-a5201e4edf98"
      },
      "source": [
        "trainX = trainX.values\n",
        "testX = testX.values\n",
        "\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "print(type(trainX))\n",
        "print(type(testX))\n",
        "\n",
        "Train_No = train_df.shape[0] \n",
        "Test_No = test_df.shape[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90000, 5)\n",
            "(10000, 5)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oJOB58XXX0q"
      },
      "source": [
        "##Create one-hot conditional matrix - numpy array\n",
        "trainlabelsX = pandas.get_dummies(train_df.Category, prefix='Category')\n",
        "testlabelsX = pandas.get_dummies(test_df.Category, prefix='Category')\n",
        "trainlabelsX = trainlabelsX.values\n",
        "testlabelsX = testlabelsX.values"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPpAMmjwXX0q"
      },
      "source": [
        "# Number of classes for conditional one-hot tensor\n",
        "nClass = 5"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXcsJ-e2WIIh"
      },
      "source": [
        "# Number of ranking features that needs imputing\n",
        "Dim = 5"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0Dzeid_VRoA"
      },
      "source": [
        "## Train GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1WXm-W1ANYs"
      },
      "source": [
        "# Set Hyperparameters\n",
        "# Mini-batch\n",
        "mb_size = 256\n",
        "# Iterations\n",
        "n_epoch = 50\n",
        "# Missing rate\n",
        "p_miss = 0.05\n",
        "# Fully-connected layer sizes (change depending on Dim)\n",
        "col1 = 64 \n",
        "col2 = 64 "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxXyeVrLXX0q"
      },
      "source": [
        "# Other functions\n",
        "def sample_M(m, n, p):\n",
        "    A = np.random.uniform(0., 1., size = [m, n])\n",
        "    B = A > p\n",
        "    C = 1.*B\n",
        "    return C\n",
        "  \n",
        "trainM = sample_M(Train_No, Dim, p_miss)\n",
        "testM = sample_M(Test_No, Dim, p_miss)\n",
        "\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
        "\n",
        "def sample_Z(m, n):\n",
        "    return np.random.uniform(0., 0.1, size = [m, n])        \n",
        "\n",
        "def sample_idx(m, n):\n",
        "    A = np.random.permutation(m)\n",
        "    idx = A[:n]\n",
        "    return idx\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur_9lEiZXX0r"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "#Tensors\n",
        "X = tf.placeholder(tf.float32, shape = [None, Dim])\n",
        "M = tf.placeholder(tf.float32, shape = [None, Dim])\n",
        "H = tf.placeholder(tf.float32, shape = [None, Dim])\n",
        "Z = tf.placeholder(tf.float32, shape = [None, Dim])\n",
        "C = tf.placeholder(tf.float32, shape = [None, nClass])\n",
        "\n",
        "D_W1 = tf.Variable(xavier_init([Dim*2 + nClass, col1]))    \n",
        "D_b1 = tf.Variable(tf.zeros(shape = [col1]))\n",
        "D_W2 = tf.Variable(xavier_init([col1, col2]))\n",
        "D_b2 = tf.Variable(tf.zeros(shape = [col2]))\n",
        "D_W3 = tf.Variable(xavier_init([col2, Dim]))\n",
        "D_b3 = tf.Variable(tf.zeros(shape = [Dim]))   \n",
        "\n",
        "G_W1 = tf.Variable(xavier_init([Dim*2 + nClass, col1]))     \n",
        "G_b1 = tf.Variable(tf.zeros(shape = [col1]))\n",
        "G_W2 = tf.Variable(xavier_init([col1, col2]))\n",
        "G_b2 = tf.Variable(tf.zeros(shape = [col2]))\n",
        "G_W3 = tf.Variable(xavier_init([col2, Dim]))\n",
        "G_b3 = tf.Variable(tf.zeros(shape = [Dim]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjoshIZeXX0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2395e498-5275-4cb1-be89-b5a6f53698d0"
      },
      "source": [
        "%%time \n",
        "#Setting up conditional generator\n",
        "def generator_conditional(x,z,m,c):\n",
        "    inp = m * x + (1-m) * z  \n",
        "    inputs = tf.concat(axis = 1, values = [inp,c,m])  \n",
        "    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "    G_est = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    return G_est\n",
        "\n",
        "    \n",
        "#Setting up conditional discriminator\n",
        "def discriminator_conditional(x, m, g, h, c):\n",
        "    inp = m * x + (1-m) * g  \n",
        "    inputs = tf.concat(axis = 1, values = [inp,c,h])  \n",
        "    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "    D_h2 = tf.nn.relu(tf.matmul(D_h1, D_W2) + D_b2)\n",
        "    D_logit = tf.matmul(D_h2, D_W3) + D_b3\n",
        "    D_prob = tf.nn.sigmoid(D_logit)  \n",
        "    return D_prob\n",
        "\n",
        "#Generate fake copies\n",
        "G_sample = generator_conditional(X,Z,M,C)\n",
        "D_prob = discriminator_conditional(X, M, G_sample, H,C)\n",
        "\n",
        "D_loss1 = -tf.reduce_mean(M * tf.log(D_prob + 1e-8) + (1-M) * tf.log(1. - D_prob + 1e-8)) * 2\n",
        "G_loss1 = -tf.reduce_mean((1-M) * tf.log(D_prob + 1e-8)) / tf.reduce_mean(1-M)\n",
        "MSE_train_loss = tf.reduce_mean((M * X - M * G_sample)**2) / tf.reduce_mean(M)\n",
        "MSE_test_loss = tf.reduce_mean(((1-M) * X - (1-M)*G_sample)**2) / tf.reduce_mean(1-M)\n",
        "\n",
        "D_loss = D_loss1 + MSE_test_loss\n",
        "G_loss = G_loss1 + 10 * MSE_train_loss \n",
        "\n",
        "\n",
        "#Imputed Copy\n",
        "Imputed_copy = M * X + (1-M) * G_sample\n",
        "\n",
        "#Adam Optimizer\n",
        "D_params = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
        "G_params = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n",
        "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=D_params)\n",
        "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=G_params)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 496 ms, sys: 6.55 ms, total: 502 ms\n",
            "Wall time: 508 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SM7ErQjdfqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbc411b-ad42-474a-a170-d48d7a980797"
      },
      "source": [
        "%%time\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "i = 1\n",
        "DiscriminatorLoss = []\n",
        "GeneratorLoss = []\n",
        "IterationsRecord = []\n",
        "\n",
        "for it in tqdm(range(n_epoch)):    \n",
        "    \n",
        "    mb_idx = sample_idx(Train_No, mb_size)\n",
        "    X_mb = trainX[mb_idx,:]  \n",
        "    Z_mb = sample_Z(mb_size, Dim) \n",
        "    M_mb = trainM[mb_idx,:]  \n",
        "    H_mb1 = sample_M(mb_size, Dim, 1-0.5)\n",
        "    H_mb = M_mb * H_mb1\n",
        "    C_mb = trainlabelsX[mb_idx, :]\n",
        "    \n",
        "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
        "    \n",
        "    _, D_loss = sess.run([D_solver, D_loss1], feed_dict = {X: X_mb, M: M_mb, Z: New_X_mb, H: H_mb, C: C_mb})\n",
        "    _, G_loss, MSE_train_loss_curr, MSE_test_loss_curr = sess.run([G_solver, G_loss1, MSE_train_loss, MSE_test_loss],\n",
        "                                                                       feed_dict = {X: X_mb, M: M_mb, Z: New_X_mb, H: H_mb, C: C_mb})\n",
        "         \n",
        "        \n",
        "    #%% Intermediate Losses\n",
        "    if it % 50 == 0:\n",
        "        IterationsRecord.append(it)\n",
        "        DiscriminatorLoss.append(D_loss)\n",
        "        GeneratorLoss.append(G_loss)\n",
        "        print('Iter: {}'.format(it))\n",
        "        print('Dloss: {:.4}'.format(D_loss))\n",
        "        print('Gloss: {:.4}'.format(G_loss))\n",
        "        print()\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 34/50 [00:00<00:00, 113.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0\n",
            "Dloss: 1.385\n",
            "Gloss: 0.6418\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 101.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 626 ms, sys: 23.1 ms, total: 649 ms\n",
            "Wall time: 607 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTrN-OW-XX0y"
      },
      "source": [
        "### Record some summary statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVZlk-9_Xwad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc7a07b-5f4e-4e12-f9bb-817201da17fe"
      },
      "source": [
        "#Getting imputations for test ranking dataset + RMSE.\n",
        "N_imputations = 10\n",
        "RMSEoutput = []\n",
        "\n",
        "for j in range(N_imputations):\n",
        "    Z_mb = sample_Z(Test_No, Dim) \n",
        "    M_mb = testM\n",
        "    X_mb = testX\n",
        "        \n",
        "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb       \n",
        "    New_C_mb = testlabelsX\n",
        "    \n",
        "    MSE_final, Sample, Imputed_copy_v2, M_v2 = sess.run([MSE_test_loss, G_sample, Imputed_copy, M], feed_dict = {X: testX, M: testM, Z: New_X_mb, C: New_C_mb})\n",
        "  \n",
        "    RMSEoutput.append(np.sqrt(MSE_final))\n",
        "    print(\"Done with imputation\", j)\n",
        "    \n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with imputation 0\n",
            "Done with imputation 1\n",
            "Done with imputation 2\n",
            "Done with imputation 3\n",
            "Done with imputation 4\n",
            "Done with imputation 5\n",
            "Done with imputation 6\n",
            "Done with imputation 7\n",
            "Done with imputation 8\n",
            "Done with imputation 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADxd7Ck0XX0y"
      },
      "source": [
        "RMSEDF = pandas.DataFrame({'RMSE': RMSEoutput})\n",
        "RMSEDF.to_csv('rmse.csv', index=False, header=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IgRDwqKizFC",
        "outputId": "02162264-fdf5-4bde-f720-3d2f168b7eaa"
      },
      "source": [
        "RMSEDF.mean(axis=0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RMSE    0.969347\n",
              "dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl3mzWfSZMhT"
      },
      "source": [
        "Code adapted based on Yoon et al. (2018)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}